#!/usr/bin/env python3
"""
–ü–∞—Ä—Å–µ—Ä —Ü–∏—Ç–∞—Ç –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
–°–æ–±–∏—Ä–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ü–∏—Ç–∞—Ç—ã —Å citaty.info –∏ –¥—Ä—É–≥–∏—Ö –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
"""

import requests
from bs4 import BeautifulSoup
import json
import re
import time
from typing import List, Dict
from urllib.parse import urljoin, urlparse

class QuotesParser:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
    def parse_citaty_info(self) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ü–∏—Ç–∞—Ç —Å citaty.info"""
        print("üîç –ü–∞—Ä—Å–∏–Ω–≥ —Ü–∏—Ç–∞—Ç —Å citaty.info...")
        
        quotes = []
        base_url = "https://citaty.info"
        
        # –°—Ç—Ä–∞–Ω–∏—Ü—ã —Å —Ü–∏—Ç–∞—Ç–∞–º–∏
        pages = [
            "/random",
            "/category/motivatsiya",
            "/category/uspekh",
            "/category/zhizn",
            "/category/mudrost",
            "/category/lyubov"
        ]
        
        for page in pages:
            try:
                url = urljoin(base_url, page)
                print(f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: {url}")
                
                response = self.session.get(url, timeout=10)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # –ò—â–µ–º —Ü–∏—Ç–∞—Ç—ã –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö
                quote_elements = soup.find_all(['div', 'blockquote', 'p'], class_=re.compile(r'quote|text|content'))
                
                for element in quote_elements:
                    quote_data = self.extract_quote_from_element(element)
                    if quote_data:
                        quotes.append(quote_data)
                
                time.sleep(2)  # –í–µ–∂–ª–∏–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {url}: {e}")
                continue
        
        return quotes
    
    def parse_wikiquote(self) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ü–∏—Ç–∞—Ç —Å –í–∏–∫–∏—Ü–∏—Ç–∞—Ç–Ω–∏–∫–∞"""
        print("üîç –ü–∞—Ä—Å–∏–Ω–≥ —Ü–∏—Ç–∞—Ç —Å –í–∏–∫–∏—Ü–∏—Ç–∞—Ç–Ω–∏–∫–∞...")
        
        quotes = []
        
        # –°—Ç—Ä–∞–Ω–∏—Ü—ã —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ —Ü–∏—Ç–∞—Ç–∞–º–∏
        pages = [
            "https://ru.wikiquote.org/wiki/–ê–ª—å–±–µ—Ä—Ç_–≠–π–Ω—à—Ç–µ–π–Ω",
            "https://ru.wikiquote.org/wiki/–°—Ç–∏–≤_–î–∂–æ–±—Å",
            "https://ru.wikiquote.org/wiki/–£–∏–Ω—Å—Ç–æ–Ω_–ß–µ—Ä—á–∏–ª–ª—å",
            "https://ru.wikiquote.org/wiki/–õ–µ–≤_–¢–æ–ª—Å—Ç–æ–π",
            "https://ru.wikiquote.org/wiki/–ê–Ω—Ç–æ–Ω_–ß–µ—Ö–æ–≤"
        ]
        
        for url in pages:
            try:
                print(f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: {url}")
                
                response = self.session.get(url, timeout=10)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –∞–≤—Ç–æ—Ä–∞ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
                author = self.extract_author_from_wikiquote(soup)
                
                # –ò—â–µ–º —Ü–∏—Ç–∞—Ç—ã
                quote_elements = soup.find_all(['li', 'p'], string=re.compile(r'[–ê-–Ø–∞-—è–Å—ë].*'))
                
                for element in quote_elements:
                    text = element.get_text().strip()
                    
                    if self.is_valid_quote(text):
                        quotes.append({
                            'text': text,
                            'author': author,
                            'source': '–í–∏–∫–∏—Ü–∏—Ç–∞—Ç–Ω–∏–∫'
                        })
                
                time.sleep(2)  # –í–µ–∂–ª–∏–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {url}: {e}")
                continue
        
        return quotes
    
    def parse_open_sources(self) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∏–∑ –¥—Ä—É–≥–∏—Ö –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        print("üîç –ü–∞—Ä—Å–∏–Ω–≥ –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤...")
        
        quotes = []
        
        # –û—Ç–∫—Ä—ã—Ç—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å —Ü–∏—Ç–∞—Ç–∞–º–∏
        sources = [
            {
                'url': 'https://ru.citaty.net/random',
                'selectors': {
                    'quote': '.quote-text',
                    'author': '.quote-author'
                }
            }
        ]
        
        for source in sources:
            try:
                print(f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: {source['url']}")
                
                response = self.session.get(source['url'], timeout=10)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # –ò—â–µ–º —Ü–∏—Ç–∞—Ç—ã –ø–æ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º
                quote_elements = soup.select(source['selectors']['quote'])
                author_elements = soup.select(source['selectors']['author'])
                
                for i, quote_elem in enumerate(quote_elements):
                    text = quote_elem.get_text().strip()
                    
                    author = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∞–≤—Ç–æ—Ä"
                    if i < len(author_elements):
                        author = author_elements[i].get_text().strip()
                    
                    if self.is_valid_quote(text):
                        quotes.append({
                            'text': text,
                            'author': author,
                            'source': '–û—Ç–∫—Ä—ã—Ç—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏'
                        })
                
                time.sleep(2)  # –í–µ–∂–ª–∏–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {source['url']}: {e}")
                continue
        
        return quotes
    
    def extract_quote_from_element(self, element) -> Dict:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ü–∏—Ç–∞—Ç—É –∏–∑ HTML —ç–ª–µ–º–µ–Ω—Ç–∞"""
        text = element.get_text().strip()
        
        if not self.is_valid_quote(text):
            return None
        
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∞–≤—Ç–æ—Ä–∞ –≤ —Ç–æ–º –∂–µ —ç–ª–µ–º–µ–Ω—Ç–µ –∏–ª–∏ —Ä—è–¥–æ–º
        author = self.extract_author_from_element(element)
        
        return {
            'text': text,
            'author': author,
            'source': 'citaty.info'
        }
    
    def extract_author_from_element(self, element) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞–≤—Ç–æ—Ä–∞ –∏–∑ HTML —ç–ª–µ–º–µ–Ω—Ç–∞"""
        # –ò—â–µ–º –∞–≤—Ç–æ—Ä–∞ –≤ –∞—Ç—Ä–∏–±—É—Ç–∞—Ö –∏–ª–∏ —Å–æ—Å–µ–¥–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö
        author_selectors = ['.author', '.quote-author', '[class*="author"]']
        
        for selector in author_selectors:
            author_elem = element.find(class_=re.compile(r'author'))
            if author_elem:
                return author_elem.get_text().strip()
        
        # –ò—â–µ–º –∞–≤—Ç–æ—Ä–∞ –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–º —ç–ª–µ–º–µ–Ω—Ç–µ
        parent = element.parent
        if parent:
            author_elem = parent.find(class_=re.compile(r'author'))
            if author_elem:
                return author_elem.get_text().strip()
        
        return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∞–≤—Ç–æ—Ä"
    
    def extract_author_from_wikiquote(self, soup) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º—è –∞–≤—Ç–æ—Ä–∞ –∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –í–∏–∫–∏—Ü–∏—Ç–∞—Ç–Ω–∏–∫–∞"""
        title = soup.find('h1')
        if title:
            return title.get_text().strip()
        return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∞–≤—Ç–æ—Ä"
    
    def is_valid_quote(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –≤–∞–ª–∏–¥–Ω–æ–π —Ü–∏—Ç–∞—Ç–æ–π"""
        if not text or len(text) < 10 or len(text) > 500:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä—É—Å—Å–∫–∏–µ –±—É–∫–≤—ã
        if not re.search(r'[–ê-–Ø–∞-—è–Å—ë]', text):
            return False
        
        # –ò—Å–∫–ª—é—á–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ–∫—Å—Ç—ã
        exclude_patterns = [
            r'^\d+$',  # –¢–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã
            r'^[–ê-–Ø–∞-—è–Å—ë\s]*$',  # –¢–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–µ –±—É–∫–≤—ã –∏ –ø—Ä–æ–±–µ–ª—ã (—Å–ª–∏—à–∫–æ–º –ø—Ä–æ—Å—Ç–æ)
            r'–∫–∞—Ç–µ–≥–æ—Ä–∏—è|—Å—Ç—Ä–∞–Ω–∏—Ü–∞|–≤–∏–∫–∏|—Å—Å—ã–ª–∫–∞',  # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å–ª–æ–≤–∞
        ]
        
        for pattern in exclude_patterns:
            if re.search(pattern, text.lower()):
                return False
        
        return True
    
    def clean_quote(self, quote: Dict) -> Dict:
        """–û—á–∏—â–∞–µ—Ç —Ü–∏—Ç–∞—Ç—É –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        text = quote['text']
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        text = re.sub(r'\s+', ' ', text).strip()
        
        # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
        text = re.sub(r'^["\']+|["\']+$', '', text)
        
        # –û—á–∏—â–∞–µ–º –∏–º—è –∞–≤—Ç–æ—Ä–∞
        author = quote['author']
        author = re.sub(r'[^\w\s\-\.]', '', author).strip()
        
        return {
            'text': text,
            'author': author,
            'source': quote.get('source', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫')
        }
    
    def remove_duplicates(self, quotes: List[Dict]) -> List[Dict]:
        """–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã —Ü–∏—Ç–∞—Ç"""
        seen_texts = set()
        unique_quotes = []
        
        for quote in quotes:
            text_lower = quote['text'].lower()
            if text_lower not in seen_texts:
                seen_texts.add(text_lower)
                unique_quotes.append(quote)
        
        return unique_quotes
    
    def save_to_json(self, data: List[Dict], filename: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ JSON —Ñ–∞–π–ª"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")
    
    def run(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        print("üöÄ –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ —Ü–∏—Ç–∞—Ç...")
        
        # –ü–∞—Ä—Å–∏–º –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        citaty_quotes = self.parse_citaty_info()
        wikiquote_quotes = self.parse_wikiquote()
        open_sources_quotes = self.parse_open_sources()
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ü–∏—Ç–∞—Ç—ã
        all_quotes = citaty_quotes + wikiquote_quotes + open_sources_quotes
        
        # –û—á–∏—â–∞–µ–º –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ–º
        cleaned_quotes = []
        for quote in all_quotes:
            cleaned = self.clean_quote(quote)
            if self.is_valid_quote(cleaned['text']):
                cleaned_quotes.append(cleaned)
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique_quotes = self.remove_duplicates(cleaned_quotes)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        result = {
            'quotes': unique_quotes,
            'totalQuotes': len(unique_quotes),
            'sources': [
                'citaty.info - –∫–æ–ª–ª–µ–∫—Ü–∏—è –º–æ—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ü–∏—Ç–∞—Ç',
                '–í–∏–∫–∏—Ü–∏—Ç–∞—Ç–Ω–∏–∫ - —Ü–∏—Ç–∞—Ç—ã –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ª–∏—á–Ω–æ—Å—Ç–µ–π',
                '–û—Ç–∫—Ä—ã—Ç—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å –±–∞–∑–∞–º–∏ —Ü–∏—Ç–∞—Ç'
            ],
            'lastUpdated': time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        self.save_to_json(result, '../src/data/parsed_quotes.json')
        
        print(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ —Ü–∏—Ç–∞—Ç: {len(unique_quotes)}")

if __name__ == "__main__":
    parser = QuotesParser()
    parser.run()
